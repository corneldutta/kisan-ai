import { Message, useConversation } from '@/components/ConversationContext';
import { GeminiLiveClient } from '@/components/GeminiLiveClient';
import { AudioRecorderLive } from '@/components/audio/AudioRecorderLive';
import { AudioStreamerLive } from '@/components/audio/AudioStreamerLive';
import { IconSymbol } from '@/components/ui/IconSymbol';
import { useRouter } from 'expo-router';
import { useEffect, useRef, useState } from 'react';
import {
    Alert,
    Image,
    SafeAreaView,
    ScrollView,
    StyleSheet,
    Text,
    TouchableOpacity,
    View
} from 'react-native';

// Replace with your backend server URL
const WEBSOCKET_SERVER_URL = __DEV__ 
  ? 'ws://localhost:8081' 
  : 'wss://your-backend-url.run.app';

export default function VoiceChatScreen() {
  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [isGeminiSpeaking, setIsGeminiSpeaking] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState('Disconnected');
  const [currentTranscription, setCurrentTranscription] = useState('');
  
  const geminiClientRef = useRef<GeminiLiveClient | null>(null);
  const audioRecorderRef = useRef<AudioRecorderLive | null>(null);
  const audioStreamerRef = useRef<AudioStreamerLive | null>(null);
  
  const { messages, addMessage } = useConversation();
  const router = useRouter();

  useEffect(() => {
    initializeComponents();
    
    return () => {
      cleanup();
    };
  }, []);

  const initializeComponents = async () => {
    try {
      setConnectionStatus('Connecting...');
      
      // Initialize Gemini Live client
      geminiClientRef.current = new GeminiLiveClient({
        serverUrl: WEBSOCKET_SERVER_URL,
        reconnectAttempts: 3,
        reconnectDelay: 2000,
      });

      // Initialize audio components
      audioRecorderRef.current = new AudioRecorderLive();
      audioStreamerRef.current = new AudioStreamerLive();

      // Set up Gemini client event listeners
      setupGeminiClientListeners();
      
      // Set up audio recorder listeners  
      setupAudioRecorderListeners();

      // Connect to backend
      const connected = await geminiClientRef.current.connect();
      if (connected) {
        setConnectionStatus('Connected');
        setIsConnected(true);
      } else {
        setConnectionStatus('Connection Failed');
        Alert.alert('Connection Error', 'Failed to connect to Kisan AI server');
      }
      
    } catch (error) {
      console.error('Error initializing components:', error);
      setConnectionStatus('Error');
      Alert.alert('Initialization Error', 'Failed to initialize voice chat components');
    }
  };

  const setupGeminiClientListeners = () => {
    if (!geminiClientRef.current) return;

    const client = geminiClientRef.current;

    client.on('connected', () => {
      setIsConnected(true);
      setConnectionStatus('Connected');
      console.log('Connected to Gemini Live API');
    });

    client.on('disconnected', () => {
      setIsConnected(false);
      setConnectionStatus('Disconnected');
      setIsGeminiSpeaking(false);
    });

    client.on('ready', () => {
      console.log('Gemini Live API ready for input');
    });

    client.on('audioData', async (audioData: string) => {
      setIsGeminiSpeaking(true);
      
      // Stream audio response through AudioStreamerLive
      if (audioStreamerRef.current) {
        await audioStreamerRef.current.addAudioChunk({
          data: audioData,
          timestamp: Date.now(),
          sampleRate: 24000, // Gemini outputs 24kHz
          channels: 1,
        });
      }
    });

    client.on('textData', (text: string) => {
      // Add AI response to conversation
      const aiMessage: Message = {
        id: Date.now().toString(),
        text: text,
        isUser: false,
        timestamp: new Date(),
        isVoice: true,
      };
      addMessage(aiMessage);
    });

    client.on('turnComplete', () => {
      setIsGeminiSpeaking(false);
      console.log('Gemini turn complete');
    });

    client.on('interrupted', () => {
      setIsGeminiSpeaking(false);
      console.log('Gemini response interrupted');
    });

    client.on('transcription', (data: any) => {
      setCurrentTranscription(data.text);
      
      // Add final transcription to conversation
      if (data.is_final) {
        const userMessage: Message = {
          id: Date.now().toString(),
          text: data.text,
          isUser: true,
          timestamp: new Date(),
          isVoice: true,
        };
        addMessage(userMessage);
        setCurrentTranscription('');
      }
    });

    client.on('error', (error: any) => {
      console.error('Gemini client error:', error);
      Alert.alert('Voice Chat Error', error.message || 'An error occurred during voice chat');
    });
  };

  const setupAudioRecorderListeners = () => {
    if (!audioRecorderRef.current) return;

    const recorder = audioRecorderRef.current;

    recorder.on('recordingStarted', () => {
      setIsRecording(true);
      console.log('Recording started');
    });

    recorder.on('recordingStopped', () => {
      setIsRecording(false);
      setIsPaused(false);
      console.log('Recording stopped');
    });

    recorder.on('recordingPaused', () => {
      setIsPaused(true);
    });

    recorder.on('recordingResumed', () => {
      setIsPaused(false);
    });

    recorder.on('audioChunk', (chunk: any) => {
      // Send audio chunk to Gemini Live API
      if (geminiClientRef.current && isConnected) {
        geminiClientRef.current.sendAudioChunk(chunk.data);
      }
    });

    recorder.on('error', (error: any) => {
      console.error('Audio recorder error:', error);
      Alert.alert('Recording Error', error.message || 'Failed to record audio');
    });
  };

  const startVoiceChat = async () => {
    if (!isConnected || !audioRecorderRef.current) {
      Alert.alert('Not Ready', 'Please wait for connection to be established');
      return;
    }

    try {
      // Stop any current Gemini playback if user starts speaking
      if (isGeminiSpeaking) {
        geminiClientRef.current?.sendInterrupt();
        audioStreamerRef.current?.stop();
      }

      const started = await audioRecorderRef.current.startRecording();
      if (!started) {
        Alert.alert('Recording Failed', 'Could not start voice recording');
      }
    } catch (error) {
      console.error('Error starting voice chat:', error);
      Alert.alert('Error', 'Failed to start voice recording');
    }
  };

  const stopVoiceChat = async () => {
    if (!audioRecorderRef.current) return;

    try {
      await audioRecorderRef.current.stopRecording();
    } catch (error) {
      console.error('Error stopping voice chat:', error);
    }
  };

  const pauseResumeRecording = async () => {
    if (!audioRecorderRef.current) return;

    try {
      if (isPaused) {
        await audioRecorderRef.current.resumeRecording();
      } else {
        await audioRecorderRef.current.pauseRecording();
      }
    } catch (error) {
      console.error('Error pausing/resuming recording:', error);
    }
  };

  const cleanup = async () => {
    try {
      if (audioRecorderRef.current) {
        await audioRecorderRef.current.cleanup();
      }
      
      if (audioStreamerRef.current) {
        await audioStreamerRef.current.cleanup();
      }
      
      if (geminiClientRef.current) {
        geminiClientRef.current.disconnect();
      }
    } catch (error) {
      console.error('Error during cleanup:', error);
    }
  };

  const switchToTextMode = () => {
    router.push('/(tabs)/text-chat');
  };

  const handleMenuPress = () => {
    Alert.alert('Menu', 'Opening side menu...');
  };

  const handleSearchPress = () => {
    Alert.alert('Search', 'Opening search...');
  };

  const handleNotificationPress = () => {
    Alert.alert('Notifications', 'Opening notifications...');
  };

  const renderMessage = (message: Message) => (
    <View
      key={message.id}
      style={[
        styles.messageContainer,
        message.isUser ? styles.userMessage : styles.aiMessage,
      ]}
    >
      <View
        style={[
          styles.messageBubble,
          message.isUser ? styles.userBubble : styles.aiBubble,
        ]}
      >
        {message.imageUri && (
          <Image source={{ uri: message.imageUri }} style={styles.messageImage} />
        )}
        <Text
          style={[
            styles.messageText,
            message.isUser ? styles.userText : styles.aiText,
          ]}
        >
          {message.text}
        </Text>
        {message.isVoice && (
          <View style={styles.voiceIndicator}>
            <IconSymbol 
              name="speaker.wave.2.fill" 
              size={16} 
              color={message.isUser ? "#FFFFFF" : "#31A05F"} 
            />
            <Text style={[
              styles.voiceLabel,
              { color: message.isUser ? "#FFFFFF" : "#31A05F" }
            ]}>
              Voice
            </Text>
          </View>
        )}
      </View>
      <Text style={styles.timestamp}>
        {message.timestamp.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}
      </Text>
    </View>
  );

  return (
    <SafeAreaView style={styles.container}>
      {/* Top Header Bar */}
      <View style={styles.header}>
        <TouchableOpacity style={styles.menuButton} onPress={handleMenuPress}>
          <IconSymbol name="line.3.horizontal" size={24} color="#FFFFFF" />
        </TouchableOpacity>
        <View style={styles.logoContainer}>
          <Text style={styles.logoText}>Kisan Mitra</Text>
          <Text style={styles.connectionStatus}>{connectionStatus}</Text>
        </View>
        <View style={styles.headerRight}>
          <TouchableOpacity style={styles.headerButton} onPress={handleSearchPress}>
            <IconSymbol name="magnifyingglass" size={24} color="#FFFFFF" />
          </TouchableOpacity>
          <TouchableOpacity style={styles.headerButton} onPress={handleNotificationPress}>
            <IconSymbol name="bell" size={24} color="#FFFFFF" />
          </TouchableOpacity>
        </View>
      </View>

      {/* Chat Messages */}
      <ScrollView style={styles.chatContainer} contentContainerStyle={styles.chatContent}>
        {messages.map(renderMessage)}
        
        {/* Show current transcription */}
        {currentTranscription && (
          <View style={styles.transcriptionContainer}>
            <Text style={styles.transcriptionText}>
              Listening: {currentTranscription}
            </Text>
          </View>
        )}
        
        {/* Show Gemini speaking indicator */}
        {isGeminiSpeaking && (
          <View style={styles.speakingIndicator}>
            <IconSymbol name="speaker.wave.3.fill" size={20} color="#31A05F" />
            <Text style={styles.speakingText}>Kisan Mitra is speaking...</Text>
          </View>
        )}
      </ScrollView>

      {/* Voice Recording Controls */}
      <View style={styles.controlsContainer}>
        <TouchableOpacity
          style={[styles.controlButton, styles.pauseButton]}
          onPress={pauseResumeRecording}
          disabled={!isRecording || !isConnected}
        >
          <IconSymbol 
            name={isPaused ? "play.fill" : "pause.fill"} 
            size={24} 
            color={isRecording && isConnected ? "#31A05F" : "#4B4B4B"} 
          />
        </TouchableOpacity>

        <TouchableOpacity
          style={[
            styles.recordButton, 
            isRecording && styles.recordingButton,
            !isConnected && styles.disabledButton
          ]}
          onPress={isRecording ? stopVoiceChat : startVoiceChat}
          disabled={!isConnected}
        >
          <IconSymbol 
            name={isRecording ? "xmark" : "mic.fill"} 
            size={32} 
            color="#FFFFFF" 
          />
        </TouchableOpacity>

        <TouchableOpacity 
          style={[styles.controlButton, styles.switchButton]} 
          onPress={switchToTextMode}
        >
          <IconSymbol name="text.bubble" size={24} color="#31A05F" />
        </TouchableOpacity>
      </View>
    </SafeAreaView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#EFEFEF',
  },
  header: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    paddingHorizontal: 16,
    paddingVertical: 12,
    backgroundColor: '#31A05F',
    paddingTop: 50,
  },
  menuButton: {
    padding: 8,
  },
  logoContainer: {
    flex: 1,
    alignItems: 'center',
  },
  logoText: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#FFFFFF',
    fontFamily: 'System',
  },
  connectionStatus: {
    fontSize: 12,
    color: '#FFFFFF',
    opacity: 0.8,
    fontFamily: 'System',
  },
  headerRight: {
    flexDirection: 'row',
    gap: 8,
  },
  headerButton: {
    padding: 8,
  },
  chatContainer: {
    flex: 1,
    backgroundColor: '#EFEFEF',
  },
  chatContent: {
    padding: 16,
    paddingBottom: 100,
  },
  messageContainer: {
    marginBottom: 16,
  },
  userMessage: {
    alignItems: 'flex-end',
  },
  aiMessage: {
    alignItems: 'flex-start',
  },
  messageBubble: {
    maxWidth: '80%',
    padding: 12,
    borderRadius: 18,
    marginBottom: 4,
  },
  userBubble: {
    backgroundColor: '#31A05F',
    borderBottomRightRadius: 4,
  },
  aiBubble: {
    backgroundColor: '#FFFFFF',
    borderBottomLeftRadius: 4,
    shadowColor: '#000000',
    shadowOffset: { width: 0, height: 1 },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 2,
  },
  messageText: {
    fontSize: 16,
    lineHeight: 20,
    fontFamily: 'System',
  },
  userText: {
    color: '#FFFFFF',
  },
  aiText: {
    color: '#4B4B4B',
  },
  voiceIndicator: {
    flexDirection: 'row',
    alignItems: 'center',
    marginTop: 4,
    alignSelf: 'flex-end',
  },
  voiceLabel: {
    marginLeft: 4,
    fontSize: 12,
    fontFamily: 'System',
  },
  messageImage: {
    width: 100,
    height: 100,
    borderRadius: 8,
    marginBottom: 4,
  },
  timestamp: {
    fontSize: 12,
    color: '#4B4B4B',
    marginHorizontal: 8,
    fontFamily: 'System',
  },
  transcriptionContainer: {
    backgroundColor: '#E3F2FD',
    padding: 12,
    borderRadius: 8,
    marginVertical: 8,
    borderLeftWidth: 4,
    borderLeftColor: '#2196F3',
  },
  transcriptionText: {
    fontSize: 14,
    color: '#1976D2',
    fontStyle: 'italic',
    fontFamily: 'System',
  },
  speakingIndicator: {
    flexDirection: 'row',
    alignItems: 'center',
    backgroundColor: '#F1F8E9',
    padding: 12,
    borderRadius: 8,
    marginVertical: 8,
    alignSelf: 'flex-start',
  },
  speakingText: {
    marginLeft: 8,
    fontSize: 14,
    color: '#31A05F',
    fontFamily: 'System',
  },
  controlsContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-around',
    paddingHorizontal: 32,
    paddingVertical: 20,
    backgroundColor: '#FFFFFF',
    borderTopWidth: 1,
    borderTopColor: '#D3EDDF',
    shadowColor: '#000000',
    shadowOffset: { width: 0, height: -2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 5,
  },
  controlButton: {
    width: 48,
    height: 48,
    borderRadius: 24,
    alignItems: 'center',
    justifyContent: 'center',
    shadowColor: '#000000',
    shadowOffset: { width: 0, height: 2 },
    shadowOpacity: 0.1,
    shadowRadius: 4,
    elevation: 3,
  },
  pauseButton: {
    backgroundColor: '#FFFFFF',
    borderWidth: 1,
    borderColor: '#D3EDDF',
  },
  recordButton: {
    width: 64,
    height: 64,
    borderRadius: 32,
    backgroundColor: '#EF9920',
    alignItems: 'center',
    justifyContent: 'center',
    shadowColor: '#000000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.2,
    shadowRadius: 6,
    elevation: 6,
  },
  recordingButton: {
    backgroundColor: '#EF9920',
    transform: [{ scale: 1.1 }],
  },
  disabledButton: {
    opacity: 0.5,
  },
  switchButton: {
    backgroundColor: '#FFFFFF',
    borderWidth: 1,
    borderColor: '#D3EDDF',
  },
}); 